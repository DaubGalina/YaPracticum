{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e3ef71",
   "metadata": {},
   "source": [
    "# Проект для Интернет-магазина c BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541831d6",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Мы обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4aff9c",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33ae08",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182f1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from tqdm import notebook\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn.svm\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe015f50",
   "metadata": {},
   "source": [
    "### Создадим токенайзер и модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca03a1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f567e5",
   "metadata": {},
   "source": [
    "### Прочитаем таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a65644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = pd.read_csv('toxic_comments.csv')\n",
    "df_tweets.info()\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b488d",
   "metadata": {},
   "source": [
    "В таблице 2 столбца. Один столбец *text* с текстами комментаторов, который нам предстоит перевести в признаки для обучения и предсказания нашей модели, а второй столбец *toxic* содержит целевой признак. Что бы хотя бы немного ускорить работу программы, переведём данные в столбце *toxic* из int64 в uint8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba6be87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  uint8 \n",
      "dtypes: object(1), uint8(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweets['toxic'] = df_tweets['toxic'].astype('uint8')\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b135bc",
   "metadata": {},
   "source": [
    "Выборку уменьшим, что бы не ждать бескнечно долго рассчётов дальнейшего эмбеддинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5412d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = df_tweets.sample(20000, replace=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a643d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df_tweets['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, truncation=True, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf5d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04da063",
   "metadata": {},
   "source": [
    "### Произведём эмбеддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a1538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a2564f132f44d4a8b13cf5dd5dbd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "batch_size = 400\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6584f756",
   "metadata": {},
   "source": [
    "### Разделим таблицу на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c8769",
   "metadata": {},
   "source": [
    "Объединим эмбеддинги, чтобы получить признаки для дальнейшей разбивки на тренировочную и тестовую выборки, а также получим целевой признак из столбца `df_tweets['toxic']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "\n",
    "target = df_tweets['toxic']\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea6799",
   "metadata": {},
   "source": [
    "## Обучим модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f6f295",
   "metadata": {},
   "source": [
    "### Модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e738c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = LogisticRegression()\n",
    "model_log.fit(features_train, target_train)\n",
    "predictions = model_log.predict(features_test)\n",
    "f1_log = f1_score(target_test, predictions)\n",
    "print('F1 модели логистической регрессии:', '{:.2f}'.format(f1_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b693d",
   "metadata": {},
   "source": [
    "### Модель случайного леса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab40d480",
   "metadata": {},
   "source": [
    "Для подбора гиперпараметров используем библиотеку *optuna*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    rf_max_depth = int(trial.suggest_loguniform('rf_max_depth', 2, 20))\n",
    "    rf_n_estimators = int(trial.suggest_loguniform('rf_n_estimators', 2, 80))\n",
    "    classifier_obj = RandomForestClassifier(max_depth=rf_max_depth, n_estimators=rf_n_estimators, random_state=12345)\n",
    "        \n",
    "    score = cross_val_score(classifier_obj, features, target, scoring='f1', n_jobs=-1, cv=5)\n",
    "    f1_score = score.mean()\n",
    "    return f1_score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb66803",
   "metadata": {},
   "source": [
    "Лучший результат с гиперпараметрами max_depth=16, rf_n_estimators=46."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomForestClassifier(max_depth=11, n_estimators=5, random_state=12345)\n",
    "model_forest.fit(features_train, target_train)\n",
    "predictions_forest = model_forest.predict(features_test)\n",
    "f1_forest = f1_score(target_test, predictions_forest)\n",
    "print('F1 модели случайного леса:', '{:.2f}'.format(f1_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d053f470",
   "metadata": {},
   "source": [
    "### Модель LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbm = LGBMClassifier(random_state=12345, class_weight='balanced')\n",
    "model_gbm.fit(features_train, target_train, verbose=10)\n",
    "\n",
    "predictions_gbm = model_gbm.predict(features_test)\n",
    "f1_gbm = f1_score(target_test, predictions_gbm)\n",
    "\n",
    "print('F1 модели градиентного бустинга библиотеки lightGBM:', '{:.2f}'.format(f1_gbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aacec1e",
   "metadata": {},
   "source": [
    "### Модель CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43605a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cat = CatBoostClassifier(iterations=100, random_seed=12345)\n",
    "model_cat.fit(features_train, target_train, verbose=10)\n",
    "\n",
    "predictions_cat = model_cat.predict(features_test)\n",
    "f1_cat = f1_score(target_test, predictions_cat)\n",
    "\n",
    "print('F1 модели градиентного бустинга библиотеки CatBoost:', '{:.2f}'.format(f1_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc7fcc",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43602890",
   "metadata": {},
   "source": [
    "Для наглядного сравнения метрик моделей сделаем таблицу и график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = pd.DataFrame(index=[\n",
    "    'Линейная регрессия', \n",
    "    'Случайный лес', \n",
    "    'LGBM', \n",
    "    'CatBoost'\n",
    "], columns=['F1'], data=[\n",
    "    f1_log, \n",
    "    f1_forest, \n",
    "    f1_gbm, \n",
    "    f1_cat]\n",
    "                          )\n",
    "\n",
    "display(final_table)\n",
    "final_table.plot.barh()\n",
    "plt.ylabel('Модели')\n",
    "plt.xlabel('F1')\n",
    "plt.title('F1 моделей')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6ed42c",
   "metadata": {},
   "source": [
    "Лучшей моделью для получения предсказаний является модель логистической регрессии."
   ]
  },
  {
   "cell_type": "raw",
   "id": "95ad127e",
   "metadata": {},
   "source": [
    "np.random.seed(0)\n",
    "param_distributions = {\"max_depth\": [2, 16], \"min_samples_split\": randint(2, 11)}\n",
    "\n",
    "search = HalvingRandomSearchCV(RandomForestClassifier(random_state=12345), \n",
    "                               param_distributions, \n",
    "                               resource='n_estimators', \n",
    "                               max_resources=80, \n",
    "                               random_state=12345).fit(features_train, target_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56e63441",
   "metadata": {},
   "source": [
    "model_tree = None\n",
    "f1_tree = 0\n",
    "\n",
    "for depth in range(1, 16):\n",
    "    model_tr = DecisionTreeClassifier(random_state=12345, max_depth=depth) # обучим модель с заданной глубиной дерева\n",
    "    model_tr.fit(features_train, target_train) # обучим модель\n",
    "    predicted_test_tr = model_tr.predict(features_test) # получим предсказания модели на валидац.выборке\n",
    "    f1_tr = f1_score(target_test, predicted_test_tr) # тут метрика\n",
    "    if f1_tr > f1_tree:\n",
    "        model_tree = model_tr\n",
    "        f1_tree = f1_tr\n",
    "        \n",
    "print('F1 модели дерева:', '{:.2f}'.format(f1_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116926d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
